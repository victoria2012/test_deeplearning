{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "multi_perceptron.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPxMw8gbcuXEPMgncj7OaNs"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoPQytK4xOhc"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxRs4VADxs0s",
        "outputId": "8edf9d89-a7c7-44c3-f056-a3389ed48a26"
      },
      "source": [
        "x_data = [[0,0],\n",
        "          [1,0],\n",
        "          [0,1],\n",
        "          [1,1]]\n",
        "y_data = [[0],   # 0.232 -> 23.2%, 0.982 -> 98.2% \n",
        "          [1],\n",
        "          [1],\n",
        "          [1]]\n",
        "type(x_data), type(y_data) "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(list, list)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXyT_tUnx02a",
        "outputId": "6081f58d-9d91-445f-c5a8-1bf60fdff20b"
      },
      "source": [
        "import numpy as np\n",
        "x_train = np.array(x_data)\n",
        "y_train = np.array(y_data)\n",
        "x_train.shape, y_train.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4, 2), (4, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFmqW5YC0uAL"
      },
      "source": [
        "## create model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n10MbgVmx8tj"
      },
      "source": [
        "model = tf.keras.models.Sequential()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_g0J6bzB09lL",
        "outputId": "52bf8c03-b01c-4ef8-e3bb-f167a312fa27"
      },
      "source": [
        "# solve XOR model\n",
        "model.add(tf.keras.Input(shape=(2,)))  # input layer\n",
        "model.add(tf.keras.layers.Dense(2, activation='sigmoid'))  # 기능 layer\n",
        "# model.add(tf.keras.layers.Dense(128, activation='sigmoid'))  # 기능 layer\n",
        "# model.add(tf.keras.layers.Dense(128, activation='sigmoid'))  # 기능 layer\n",
        "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))                         #  output layer\n",
        "                  # 시그모이드를 쓴다는 함수 : 활성화 함수(activation function)\n",
        "                                                          # units와 activation은 꼭 넣어줘야 한다. units는 노드의 숫자와 같다. \n",
        "model.compile(optimizer='sgd', loss='mse', metrics=['acc'])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1l2DWvvd8xY7"
      },
      "source": [
        "# tf.keras.utils.plot_model(model, show_shapes=True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FF3a6rM48VAJ",
        "outputId": "a59b49e0-707c-4b31-c57c-c8c34adb7b95"
      },
      "source": [
        "model.fit(x_train, y_train, epochs=100)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 1s 697ms/step - loss: 0.2421 - acc: 0.7500\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2417 - acc: 0.7500\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2414 - acc: 0.7500\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2411 - acc: 0.7500\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2408 - acc: 0.7500\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2405 - acc: 0.7500\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2401 - acc: 0.7500\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2398 - acc: 0.7500\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2395 - acc: 0.7500\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2392 - acc: 0.7500\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2389 - acc: 0.7500\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2386 - acc: 0.7500\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2383 - acc: 0.7500\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2379 - acc: 0.7500\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2376 - acc: 0.7500\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2373 - acc: 0.7500\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2370 - acc: 0.7500\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2367 - acc: 0.7500\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2364 - acc: 0.7500\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2361 - acc: 0.7500\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2358 - acc: 0.7500\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2355 - acc: 0.7500\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2352 - acc: 0.7500\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2349 - acc: 0.7500\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2347 - acc: 0.7500\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2344 - acc: 0.7500\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2341 - acc: 0.7500\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2338 - acc: 0.7500\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2335 - acc: 0.7500\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2332 - acc: 0.7500\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2329 - acc: 0.7500\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2326 - acc: 0.7500\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2324 - acc: 0.7500\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2321 - acc: 0.7500\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2318 - acc: 0.7500\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2315 - acc: 0.7500\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2313 - acc: 0.7500\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2310 - acc: 0.7500\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2307 - acc: 0.7500\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2304 - acc: 0.7500\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2302 - acc: 0.7500\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2299 - acc: 0.7500\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2296 - acc: 0.7500\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2294 - acc: 0.7500\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2291 - acc: 0.7500\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2288 - acc: 0.7500\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2286 - acc: 0.7500\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2283 - acc: 0.7500\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2281 - acc: 0.7500\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2278 - acc: 0.7500\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2275 - acc: 0.7500\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2273 - acc: 0.7500\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2270 - acc: 0.7500\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2268 - acc: 0.7500\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2265 - acc: 0.7500\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2263 - acc: 0.7500\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2260 - acc: 0.7500\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2258 - acc: 0.7500\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2255 - acc: 0.7500\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2253 - acc: 0.7500\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2250 - acc: 0.7500\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2248 - acc: 0.7500\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2245 - acc: 0.7500\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2243 - acc: 0.7500\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2241 - acc: 0.7500\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2238 - acc: 0.7500\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2236 - acc: 0.7500\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2233 - acc: 0.7500\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2231 - acc: 0.7500\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2229 - acc: 0.7500\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2226 - acc: 0.7500\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2224 - acc: 0.7500\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2222 - acc: 0.7500\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2220 - acc: 0.7500\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2217 - acc: 0.7500\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2215 - acc: 0.7500\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2213 - acc: 0.7500\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2210 - acc: 0.7500\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2208 - acc: 0.7500\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2206 - acc: 0.7500\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2204 - acc: 0.7500\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2202 - acc: 0.7500\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2199 - acc: 0.7500\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2197 - acc: 0.7500\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2195 - acc: 0.7500\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2193 - acc: 0.7500\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.2191 - acc: 0.7500\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2189 - acc: 0.7500\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.2186 - acc: 0.7500\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2184 - acc: 0.7500\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2182 - acc: 0.7500\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2180 - acc: 0.7500\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2178 - acc: 0.7500\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2176 - acc: 0.7500\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2174 - acc: 0.7500\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2172 - acc: 0.7500\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.2170 - acc: 0.7500\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.2168 - acc: 0.7500\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2166 - acc: 0.7500\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.2164 - acc: 0.7500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7faa056be850>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iv6MLJse9cOM"
      },
      "source": [
        "# model.predict([[0,1]])     # epochs : 100, loss : 0.3270"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkXWhR0IACwr"
      },
      "source": [
        "# model.predict([[0,1]])     # epochs : 100, loss : 0.1999"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcTlyfaPAOby",
        "outputId": "560d6f5f-651a-4a21-a5b2-abf255f34b38"
      },
      "source": [
        "model.predict([[0,1]])       # 성능을 좋게 하려면 epochs를 높이거나 Dense값을 올리거나 기능 layer를 더 늘린다.   loss는 낮으면 낮을수록 좋고 정확도는 높으면 높을수록 좋다. "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.56646186]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJwbGkTo-1jT",
        "outputId": "911f6d0a-7d9d-4869-e2c8-41be0fa4bf7f"
      },
      "source": [
        "model.evaluate(x_train, y_train)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 125ms/step - loss: 0.2162 - acc: 0.7500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.21615999937057495, 0.75]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wQ3e220CX4c"
      },
      "source": [
        ""
      ],
      "execution_count": 11,
      "outputs": []
    }
  ]
}